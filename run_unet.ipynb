{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b00e5a16",
   "metadata": {},
   "source": [
    "# Run Pipeline - Simple UNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7dc61440",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "A bite-size U-Net demo that prints tensor shapes to illustrate\n",
    "concatenating skip connections.\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "\n",
    "# ---------- 1. Reproducibility ------------------------------------------------\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "random.seed(0)\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9017b29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- 2. Synthetic Segmentation Dataset --------------------------------\n",
    "class CircleDataset(Dataset):\n",
    "    \"\"\"64×64 images containing a single filled circle + noise; mask is circle.\"\"\"\n",
    "    def __init__(self, n_samples: int):\n",
    "        self.n = n_samples\n",
    "        self.size = 64\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        H = W = self.size\n",
    "        img  = torch.zeros((H, W), dtype=torch.float32)\n",
    "        mask = torch.zeros((H, W), dtype=torch.float32)\n",
    "\n",
    "        # random circle\n",
    "        radius = random.randint(5, 15)\n",
    "        cx = random.randint(radius + 1, W - radius - 2)\n",
    "        cy = random.randint(radius + 1, H - radius - 2)\n",
    "\n",
    "        yy, xx = torch.meshgrid(torch.arange(H), torch.arange(W), indexing='ij')\n",
    "        circle = ((xx - cx) ** 2 + (yy - cy) ** 2) <= radius ** 2\n",
    "        mask[circle] = 1.0\n",
    "        img[circle] = 1.0    # base signal\n",
    "\n",
    "        # add slight noise\n",
    "        img += 0.1 * torch.rand_like(img)\n",
    "        img = img.clamp(0.0, 1.0)\n",
    "\n",
    "        return img.unsqueeze(0), mask.unsqueeze(0)  # channel dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "209d2563",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- 3. Network Building Blocks ---------------------------------------\n",
    "class DoubleConv(nn.Module):\n",
    "    \"\"\"(Conv → ReLU) × 2\"\"\"\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(in_ch, out_ch, 3, padding=1, bias=False),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_ch, out_ch, 3, padding=1, bias=False),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "class DownBlock(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, pool=True):\n",
    "        super().__init__()\n",
    "        self.double_conv = DoubleConv(in_ch, out_ch)\n",
    "        self.pool   = nn.MaxPool2d(2) if pool else None\n",
    "\n",
    "    def forward(self, x, verbose=False, tag=\"\"):\n",
    "        x = self.double_conv(x)\n",
    "        if verbose:\n",
    "            print(f\"{tag} feat: {x.shape}\")\n",
    "        if self.pool is None:\n",
    "            return x                           # bottom – no pool, no skip\n",
    "        pooled = self.pool(x)\n",
    "        if verbose:\n",
    "            print(f\"{tag} pool: {pooled.shape}\")\n",
    "        return x, pooled\n",
    "\n",
    "class UpBlock(nn.Module):\n",
    "    \"\"\"Up-sample, concatenate skip, DoubleConv\"\"\"\n",
    "    def __init__(self, in_ch, skip_ch, out_ch):\n",
    "        super().__init__()\n",
    "        self.up = nn.ConvTranspose2d(in_ch, in_ch // 2, kernel_size=2, stride=2)\n",
    "        self.double_conv = DoubleConv(in_ch // 2 + skip_ch, out_ch)\n",
    "\n",
    "    def forward(self, x, skip, verbose=False, tag=\"\"):\n",
    "        x = self.up(x)\n",
    "        if verbose:\n",
    "            print(f\"{tag} up   : {x.shape}\")\n",
    "            print(f\"{tag} skip : {skip.shape}\")\n",
    "        x = torch.cat([x, skip], dim=1)   # concat channels\n",
    "        if verbose:\n",
    "            print(f\"{tag} cat  : {x.shape}\")\n",
    "        x = self.double_conv(x)\n",
    "        if verbose:\n",
    "            print(f\"{tag} out  : {x.shape}\")\n",
    "        return x\n",
    "\n",
    "# ---------- 4. Mini-U-Net -----------------------------------------------------\n",
    "class MiniUNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.d1 = DownBlock(1, 16, pool=True)\n",
    "        self.d2 = DownBlock(16, 32, pool=True)\n",
    "        self.bottom = DownBlock(32, 64, pool=False)   # ← no max-pool here\n",
    "\n",
    "        self.u2 = UpBlock(64, 32, 32)\n",
    "        self.u1 = UpBlock(32, 16, 16)\n",
    "\n",
    "        self.final = nn.Conv2d(16, 1, kernel_size=1)\n",
    "        self._verbose_once = True  # only print shapes once\n",
    "\n",
    "    def forward(self, x):\n",
    "        verbose = False\n",
    "        if self._verbose_once:\n",
    "            verbose = True\n",
    "            self._verbose_once = False\n",
    "\n",
    "        s1, x = self.d1(x, verbose, \"Down1\")\n",
    "        s2, x = self.d2(x, verbose, \"Down2\")\n",
    "        x     = self.bottom(x, verbose, \"Bottom\")      # returns only x (16×16)\n",
    "\n",
    "        x = self.u2(x, s2, verbose, \"Up2\")\n",
    "        x = self.u1(x, s1, verbose, \"Up1\")\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"Final conv input: {x.shape}\")\n",
    "        logits = self.final(x)   # (B,1,64,64)\n",
    "        if verbose:\n",
    "            print(f\"Logits out: {logits.shape}\\n\")\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "beadde9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- 5. Metrics --------------------------------------------------------\n",
    "def dice_accuracy(logits, masks):\n",
    "    \"\"\"Simple pixel accuracy (threshold 0.5).\"\"\"\n",
    "    preds = (torch.sigmoid(logits) > 0.5).float()\n",
    "    return (preds == masks).float().mean().item()\n",
    "\n",
    "# ---------- 6. Training -------------------------------------------------------\n",
    "def train_epoch(model, loader, crit, opt, epoch):\n",
    "    model.train()\n",
    "    running_loss, running_acc = 0.0, 0.0\n",
    "    for imgs, masks in loader:\n",
    "        imgs, masks = imgs.to(DEVICE), masks.to(DEVICE)\n",
    "\n",
    "        opt.zero_grad()\n",
    "        logits = model(imgs)\n",
    "        loss = crit(logits, masks)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "        running_loss += loss.item() * imgs.size(0)\n",
    "        running_acc  += dice_accuracy(logits, masks) * imgs.size(0)\n",
    "\n",
    "    n = len(loader.dataset)\n",
    "    print(f\"[Epoch {epoch:02}] \"\n",
    "          f\"loss={running_loss/n:.4f}  acc={running_acc/n:.3f}\")\n",
    "\n",
    "def validate(model, loader, crit):\n",
    "    model.eval()\n",
    "    val_loss, val_acc = 0.0, 0.0\n",
    "    with torch.no_grad():\n",
    "        for imgs, masks in loader:\n",
    "            imgs, masks = imgs.to(DEVICE), masks.to(DEVICE)\n",
    "            logits = model(imgs)\n",
    "            val_loss += crit(logits, masks).item() * imgs.size(0)\n",
    "            val_acc  += dice_accuracy(logits, masks) * imgs.size(0)\n",
    "    n = len(loader.dataset)\n",
    "    return val_loss/n, val_acc/n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7028700a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiceLoss(nn.Module):\n",
    "    \"\"\"Soft Dice loss for logits; works with BCEWithLogits-style output.\"\"\"\n",
    "    def __init__(self, eps: float = 1e-6):\n",
    "        super().__init__()\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, logits, targets):\n",
    "        probs = torch.sigmoid(logits)\n",
    "        num   = 2 * (probs * targets).sum(dim=(1,2,3)) + self.eps\n",
    "        den   = probs.sum(dim=(1,2,3)) + targets.sum(dim=(1,2,3)) + self.eps\n",
    "        dice  = num / den\n",
    "        return 1 - dice.mean()                      # minimise (1-dice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7237ca1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    train_ds = CircleDataset(200)\n",
    "    val_ds   = CircleDataset(50)\n",
    "    train_loader = DataLoader(train_ds, batch_size=16, shuffle=True)\n",
    "    val_loader   = DataLoader(val_ds, batch_size=16)\n",
    "\n",
    "    model = MiniUNet().to(DEVICE)\n",
    "    # criterion = nn.BCEWithLogitsLoss()\n",
    "    criterion = DiceLoss() # custom loss function\n",
    "    optimiser = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "    for epoch in range(1, 6):\n",
    "        train_epoch(model, train_loader, criterion, optimiser, epoch)\n",
    "        v_loss, v_acc = validate(model, val_loader, criterion)\n",
    "        print(f\"          ↳ val_loss={v_loss:.4f}  val_acc={v_acc:.3f}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bbaec3fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Down1 feat: torch.Size([16, 16, 64, 64])\n",
      "Down1 pool: torch.Size([16, 16, 32, 32])\n",
      "Down2 feat: torch.Size([16, 32, 32, 32])\n",
      "Down2 pool: torch.Size([16, 32, 16, 16])\n",
      "Bottom feat: torch.Size([16, 64, 16, 16])\n",
      "Up2 up   : torch.Size([16, 32, 32, 32])\n",
      "Up2 skip : torch.Size([16, 32, 32, 32])\n",
      "Up2 cat  : torch.Size([16, 64, 32, 32])\n",
      "Up2 out  : torch.Size([16, 32, 32, 32])\n",
      "Up1 up   : torch.Size([16, 16, 64, 64])\n",
      "Up1 skip : torch.Size([16, 16, 64, 64])\n",
      "Up1 cat  : torch.Size([16, 32, 64, 64])\n",
      "Up1 out  : torch.Size([16, 16, 64, 64])\n",
      "Final conv input: torch.Size([16, 16, 64, 64])\n",
      "Logits out: torch.Size([16, 1, 64, 64])\n",
      "\n",
      "[Epoch 01] loss=0.8576  acc=0.081\n",
      "          ↳ val_loss=0.8265  val_acc=0.079\n",
      "\n",
      "[Epoch 02] loss=0.7792  acc=0.100\n",
      "          ↳ val_loss=0.7928  val_acc=0.138\n",
      "\n",
      "[Epoch 03] loss=0.7454  acc=0.598\n",
      "          ↳ val_loss=0.6697  val_acc=0.954\n",
      "\n",
      "[Epoch 04] loss=0.6836  acc=0.963\n",
      "          ↳ val_loss=0.5108  val_acc=0.994\n",
      "\n",
      "[Epoch 05] loss=0.2216  acc=0.991\n",
      "          ↳ val_loss=0.0401  val_acc=0.998\n",
      "\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
